[
  {
    "objectID": "lec-1/lecture-1.html",
    "href": "lec-1/lecture-1.html",
    "title": "Lecture 1",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker, cm\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom scipy.interpolate import splrep, BSpline\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.pyplot import subplots\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport sklearn\nimport warnings\nwarnings.filterwarnings('ignore')",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lec-1/lecture-1.html#linear-regression-example",
    "href": "lec-1/lecture-1.html#linear-regression-example",
    "title": "Lecture 1",
    "section": "Linear Regression example",
    "text": "Linear Regression example\n\nSpecify parameters\n\nn = 100\np = 1\nbeta = 3\nsigma = 1\n\n\n\nGenerate data\n\nx = np.random.normal(size=(n, p))\ny = x * beta + np.random.normal(size=(n, 1)) * sigma\n\ncolnames = ['x' + str(i) for i in range(1, p+1)]\ncolnames.insert(0, 'y')\n\ndf = pd.DataFrame(np.hstack((y, x)), columns = colnames)\n\n\n\nFit linear regression model using sklearn\n\nlm = LinearRegression()\nlm.fit(x, y)\ny_hat = lm.predict(x)\nresid = y - y_hat\n\n\n\nPlot x vs y using seaborn\n\nsns.set_theme()\nlm_plot = sns.relplot(df, x='x1', y='y', height = 3, aspect = 1.2)\nplt.axline((0,lm.intercept_[0]), slope=lm.coef_[0][0])\n\n\n\n\n\n\n\n\n\n\nPlot x vs y, including residual distances\n\ny_min = np.minimum(y, y_hat)\ny_max = np.maximum(y, y_hat)\nlm_plot = sns.relplot(df, x='x1', y='y', height = 3, aspect = 1.2)\nplt.axline((0,lm.intercept_[0]), slope=lm.coef_[0][0])\nlm_plot.ax.vlines(x=list(x[:,0]), ymin=list(y_min[:,0]), ymax=list(y_max[:,0]), color = 'red', alpha=0.5)\n\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lec-1/lecture-1.html#overfitting-example",
    "href": "lec-1/lecture-1.html#overfitting-example",
    "title": "Lecture 1",
    "section": "Overfitting example",
    "text": "Overfitting example\n\nsort_ind = np.argsort(x, axis=0)\nxsort = np.take_along_axis(x, sort_ind, axis=0)\nysort = np.take_along_axis(y, sort_ind, axis=0)\ntck = splrep(xsort, ysort, s=20)\n\nxspline = np.arange(x.min(), x.max(), 0.01)\nyspline = BSpline(*tck)(xspline)\n\nlm_plot = sns.relplot(df, x='x1', y='y', height = 3.5, aspect = 1.2)\nplt.axline((0,lm.intercept_[0]), slope=lm.coef_[0][0], label = \"Linear Regression\")\nplt.plot(xspline, yspline,color='orange', label = \"Spline\")\nplt.legend(loc='upper left')",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lec-1/lecture-1.html#shrinkage-plot",
    "href": "lec-1/lecture-1.html#shrinkage-plot",
    "title": "Lecture 1",
    "section": "Shrinkage plot",
    "text": "Shrinkage plot\n\nn = 100\np = 90\nbeta = np.zeros(p)\nbeta[0]=3\nbeta[1]=3\ncov = 0.6 * np.ones((p, p))\nnp.fill_diagonal(cov, 1)\nx = np.random.multivariate_normal(mean=np.zeros(p), cov=cov, size=n)\ny = np.matmul(x, beta) + np.random.normal(size=n)\n\nbeta1 = np.arange(-5, 10, 0.05)\nbeta2 = np.arange(-5, 10, 0.05)\n\nbeta_plot = [np.array((i, j)) for i in beta1 for j in beta2]\n\ndef ls_func(beta):\n    beta_full = np.zeros(p)\n    beta_full[0] = beta[0]\n    beta_full[1] = beta[1]\n    sum_square = 0.5 * np.sum(np.power(y - np.matmul(x, beta_full), 2))\n    return sum_square\n\nout = [ls_func(i) for i in beta_plot]\n\nz = np.array(out)\nz = np.reshape(z, (len(beta1), len(beta2)))\nz = np.transpose(z)\n\nlev_exp = np.linspace(np.log10(z.min()), np.log10(z.max()), num = 15)\nlevs = np.power(10, lev_exp)\n\nfig, ax = plt.subplots(1, 2)\nfig.set_size_inches(8, 4)\ncs = ax[0].contourf(beta1, beta2, z, levels=levs, cmap=cm.PuBu_r)\nax[0].plot(beta[0], beta[1], marker = '.', ls='none')\nax[0].annotate(r'$\\beta^*$', (beta[0] + 0.1, beta[1] + 0.1), fontsize=14, color='white')\nax[0].set_xlabel(r'$\\beta_1$', fontsize=14)\nax[0].set_ylabel(r'$\\beta_2$', fontsize=14)\n\nalpha = 2\nx_fill = np.linspace(-alpha, alpha, 500)\ny_ridge_up = np.sqrt(alpha**2-x_fill**2)\ny_ridge_down = -np.sqrt(alpha**2-x_fill**2)\nax[0].fill_between(x_fill, y_ridge_down, y_ridge_up, color='orange')\n\ncs = ax[1].contourf(beta1, beta2, z, levels=levs, cmap=cm.PuBu_r)\nax[1].plot(beta[0], beta[1], marker = '.', ls='none')\nax[1].annotate(r'$\\beta^*$', (beta[0] + 0.1, beta[1] + 0.1), fontsize=14, color='white')\nax[1].set_xlabel(r'$\\beta_1$', fontsize=14)\nax[1].set_ylabel(r'$\\beta_2$', fontsize=14)\n\nx_fill = np.linspace(-alpha, alpha, 500)\ny_lasso_up = (x_fill+alpha) * (x_fill &lt; 0) + (-x_fill + alpha) * (x_fill &gt; 0)\ny_lasso_down = -(x_fill+alpha) * (x_fill &lt; 0) + -(-x_fill + alpha) * (x_fill &gt; 0)\nax[1].fill_between(x_fill, y_lasso_down, y_lasso_up, color='orange')\n\nfig.tight_layout()",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lec-1/lecture-1.html#lasso-example",
    "href": "lec-1/lecture-1.html#lasso-example",
    "title": "Lecture 1",
    "section": "Lasso example",
    "text": "Lasso example\nThis code is adapted from https://github.com/intro-stat-learning/ISLP_labs/blob/stable/Ch06-varselect-lab.ipynb\n\nn = 100\np = 90\nbeta = np.zeros(p)\nbeta[0]=3\nbeta[1]=3\ncov = 0.6 * np.ones((p, p))\nnp.fill_diagonal(cov, 1)\nx = np.random.multivariate_normal(mean=np.zeros(p), cov=cov, size=n)\ny = np.matmul(x, beta) + np.random.normal(size=n)\n\nx_columns = ['x' + str(i+1) for i in range(p)]\n\n\n# set up cross-validation\nK=5\nkfold = sklearn.model_selection.KFold(K,random_state=0,shuffle=True)\n\n# function to standardize input\nscaler = StandardScaler(with_mean=True, with_std=True)\n\n\nlassoCV = sklearn.linear_model.ElasticNetCV(n_alphas=100, l1_ratio=1,cv=kfold)\npipeCV = Pipeline(steps=[('scaler', scaler),('lasso', lassoCV)])\npipeCV.fit(x, y)\ntuned_lasso = pipeCV.named_steps['lasso']\ntuned_lasso.alpha_\n\nlambdas, soln_array = sklearn.linear_model.Lasso.path(x, y,l1_ratio=1,n_alphas=100)[:2]\nsoln_path = pd.DataFrame(soln_array.T,columns=x_columns, index=-np.log(lambdas))\n\n\npath_fig, ax = subplots(figsize=(8,8))\nsoln_path.plot(ax=ax, legend=False)\nax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\nax.set_ylabel('Standardized coefficiients', fontsize=20);\n\n\n\n\n\n\n\n\n\nlassoCV_fig, ax = subplots(figsize=(8,8))\nax.errorbar(-np.log(tuned_lasso.alphas_),tuned_lasso.mse_path_.mean(1),yerr=tuned_lasso.mse_path_.std(1) / np.sqrt(K))\nax.axvline(-np.log(tuned_lasso.alpha_), c='k', ls='--')\nax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\nax.set_ylabel('Cross-validated MSE', fontsize=20);",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lec-1/lecture-1.html#ridge-regression",
    "href": "lec-1/lecture-1.html#ridge-regression",
    "title": "Lecture 1",
    "section": "Ridge regression",
    "text": "Ridge regression\nThis code is adapted from https://github.com/intro-stat-learning/ISLP_labs/blob/stable/Ch06-varselect-lab.ipynb\n\nlambdas = 10**np.linspace(8, -2, 100) / y.std()\nridgeCV = sklearn.linear_model.ElasticNetCV(alphas=lambdas, \n                           l1_ratio=0,\n                           cv=kfold)\npipeCV = Pipeline(steps=[('scaler', scaler),\n                         ('ridge', ridgeCV)])\npipeCV.fit(x, y)\n\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+03, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.932e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.260e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.570e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.882e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.212e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.576e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.985e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.448e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.966e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.540e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.165e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.836e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.840e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.259e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.898e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+02, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.590e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.368e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.264e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.277e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.403e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.637e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.892e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+01, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+00, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.413e+00, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.139e+00, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e+00, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.145e+00, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e+00, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e+00, tolerance: 2.918e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+03, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.610e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.943e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.262e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.584e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.926e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.303e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.726e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.641e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.114e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.890e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.492e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+02, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.872e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.694e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.626e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.669e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.819e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.072e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.422e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.860e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.379e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+01, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.940e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.916e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.795e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.130e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e+00, tolerance: 2.855e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.540e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.534e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+03, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.397e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.638e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.886e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.160e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.475e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.845e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.275e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.769e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.324e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.938e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.602e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.310e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.621e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.254e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+02, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.010e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.853e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.847e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.000e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.603e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.041e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+01, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.529e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.338e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.499e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.790e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e+00, tolerance: 3.090e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+03, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.698e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.219e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.697e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.140e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.563e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.980e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.853e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.334e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.858e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.428e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.045e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.707e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.409e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.705e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.839e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+02, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.810e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.631e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.546e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.558e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.666e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.867e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.158e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.534e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.988e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.514e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+01, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.920e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.140e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.655e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.403e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.878e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+00, tolerance: 2.474e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+03, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.778e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.151e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.504e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.853e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.215e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.605e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.035e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.513e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.042e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.624e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.928e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.623e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+02, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.763e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.583e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.521e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.575e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.741e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.014e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.385e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+01, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.518e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.859e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.470e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.308e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.340e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.535e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.870e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e+00, tolerance: 2.800e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.314e+01, tolerance: 3.539e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  model = cd_fast.enet_coordinate_descent(\n\n\nPipeline(steps=[('scaler', StandardScaler()),\n                ('ridge',\n                 ElasticNetCV(alphas=array([1.68106317e+07, 1.33221381e+07, 1.05575666e+07, 8.36669100e+06,\n       6.63045953e+06, 5.25452579e+06, 4.16412182e+06, 3.29999533e+06,\n       2.61518987e+06, 2.07249324e+06, 1.64241545e+06, 1.30158616e+06,\n       1.03148477e+06, 8.17434041e+05, 6.47802498e+05, 5.13372401e+05,\n       4.06838849e+05, 3.22412830e+05,...\n       1.39564817e-01, 1.10602731e-01, 8.76507729e-02, 6.94617385e-02,\n       5.50472399e-02, 4.36239962e-02, 3.45712709e-02, 2.73971410e-02,\n       2.17117657e-02, 1.72062030e-02, 1.36356216e-02, 1.08059970e-02,\n       8.56356779e-03, 6.78648102e-03, 5.37817015e-03, 4.26210787e-03,\n       3.37764760e-03, 2.67672796e-03, 2.12126113e-03, 1.68106317e-03]),\n                              cv=KFold(n_splits=5, random_state=0, shuffle=True),\n                              l1_ratio=0))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('scaler', StandardScaler()),\n                ('ridge',\n                 ElasticNetCV(alphas=array([1.68106317e+07, 1.33221381e+07, 1.05575666e+07, 8.36669100e+06,\n       6.63045953e+06, 5.25452579e+06, 4.16412182e+06, 3.29999533e+06,\n       2.61518987e+06, 2.07249324e+06, 1.64241545e+06, 1.30158616e+06,\n       1.03148477e+06, 8.17434041e+05, 6.47802498e+05, 5.13372401e+05,\n       4.06838849e+05, 3.22412830e+05,...\n       1.39564817e-01, 1.10602731e-01, 8.76507729e-02, 6.94617385e-02,\n       5.50472399e-02, 4.36239962e-02, 3.45712709e-02, 2.73971410e-02,\n       2.17117657e-02, 1.72062030e-02, 1.36356216e-02, 1.08059970e-02,\n       8.56356779e-03, 6.78648102e-03, 5.37817015e-03, 4.26210787e-03,\n       3.37764760e-03, 2.67672796e-03, 2.12126113e-03, 1.68106317e-03]),\n                              cv=KFold(n_splits=5, random_state=0, shuffle=True),\n                              l1_ratio=0))])StandardScalerStandardScaler()ElasticNetCVElasticNetCV(alphas=array([1.68106317e+07, 1.33221381e+07, 1.05575666e+07, 8.36669100e+06,\n       6.63045953e+06, 5.25452579e+06, 4.16412182e+06, 3.29999533e+06,\n       2.61518987e+06, 2.07249324e+06, 1.64241545e+06, 1.30158616e+06,\n       1.03148477e+06, 8.17434041e+05, 6.47802498e+05, 5.13372401e+05,\n       4.06838849e+05, 3.22412830e+05, 2.55506654e+05, 2.02484654e+05,\n       1.60465625e+05, 1.271662...\n       1.39564817e-01, 1.10602731e-01, 8.76507729e-02, 6.94617385e-02,\n       5.50472399e-02, 4.36239962e-02, 3.45712709e-02, 2.73971410e-02,\n       2.17117657e-02, 1.72062030e-02, 1.36356216e-02, 1.08059970e-02,\n       8.56356779e-03, 6.78648102e-03, 5.37817015e-03, 4.26210787e-03,\n       3.37764760e-03, 2.67672796e-03, 2.12126113e-03, 1.68106317e-03]),\n             cv=KFold(n_splits=5, random_state=0, shuffle=True), l1_ratio=0)\n\n\n\nlambdas, soln_array = sklearn.linear_model.ElasticNet.path(x, y,l1_ratio=0,alphas=lambdas)[:2]\nsoln_path = pd.DataFrame(soln_array.T,columns=x_columns, index=-np.log(lambdas))\n\npath_fig, ax = subplots(figsize=(8,8))\nsoln_path.plot(ax=ax, legend=False)\nax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\nax.set_ylabel('Standardized coefficiients', fontsize=20);\n\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.1622532218792, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.160659531988, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.1586485284088, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.1561109376285, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.1529088738603, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.148868347755, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.143769814084, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.1373362452396, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.1292180832554, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.118974253881, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.106048213, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.089737726905, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.0691567493125, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.043187331501, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1787.0104189650835, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.9690720815388, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.9169015836742, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.8510752181649, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.7680202615065, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.6632303180425, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.5310219379123, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.3642281578436, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1786.1538128338, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1785.888385638018, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1785.553592683464, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1785.1313517550761, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1784.5988939106649, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1783.9275646352137, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1783.0813277359487, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1782.0149038523246, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1780.671463211446, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1778.979779967677, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1776.8507448295206, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1774.1731267160915, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1770.808477950553, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1766.5850990707047, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1761.2910311282174, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1754.6661436033612, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1746.3935602249562, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1736.0909460563082, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1723.302605324679, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1707.4939455304013, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1688.0506617720837, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1664.2859396631566, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1635.4599033453437, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1600.8160957240598, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1559.639372971284, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1511.3374083138099, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1455.5432298780102, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1392.2286236790128, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1321.8089457884985, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1245.2120576227792, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1163.882543859122, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1079.7014650395677, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 994.8221008508156, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 911.447540304224, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 831.595775973278, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 756.9024008260883, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 688.4977974291874, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 626.9716341791649, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 572.4137510447949, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524.5058929766999, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 482.6357049911579, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 446.00996918540955, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 413.7531971467933, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384.9862058498111, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 358.8850422160973, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 334.7232108718829, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 311.90028558177454, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289.95876391671834, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 268.5896251480157, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247.62642090762014, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 227.02832090549072, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206.85411784898673, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187.2309354055531, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 168.32230830203736, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 150.29988392666797, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 133.32144337191653, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117.51604938992735, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102.97562819510213, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89.75170587810888, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77.85602927654733, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.26435002286067, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.92138120661631, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.74890409360814, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.65206180478708, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.5279924770643, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.27069943998797, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.776606147606724, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.94806162658936, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.6951500161271, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.93684365738462, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.601494432193642, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.626630231677886, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.958422542370144, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.550976715712835, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.365498324674753, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.36918887228393, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.534199002955075, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio &gt; 0 to add L1 regularization.\n  model = cd_fast.enet_coordinate_descent_gram(\n/Users/gemma/miniconda3/envs/msds534/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.836837852020588, tolerance: 0.3574336678728705\n  model = cd_fast.enet_coordinate_descent_gram(\n\n\n\n\n\n\n\n\n\n\ntuned_ridge = pipeCV.named_steps['ridge']\nridgeCV_fig, ax = subplots(figsize=(8,8))\nax.errorbar(-np.log(lambdas),\n            tuned_ridge.mse_path_.mean(1),\n            yerr=tuned_ridge.mse_path_.std(1) / np.sqrt(K))\nax.axvline(-np.log(tuned_ridge.alpha_), c='k', ls='--')\nax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\nax.set_ylabel('Cross-validated MSE', fontsize=20);",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lec-1/lecture-1.html#logistic-regression",
    "href": "lec-1/lecture-1.html#logistic-regression",
    "title": "Lecture 1",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nData\n\nn = 100\np = 2\nx = np.random.uniform(-2, 2, size=(n, p))\n\nbeta = np.array([2.5, -2.5])\nmu = np.matmul(x, beta)\nprob = 1/(1 + np.exp(-mu))\n\ny = np.zeros((n))\nfor i in range(n):\n    y[i] = np.random.binomial(1, prob[i], 1)[0]\n\ndf = np.hstack([y.reshape((n, 1)), x])\ndf = pd.DataFrame(df, columns = ['y', 'x1', 'x2'])\n\nsns.set_theme()\nlogit_plot = sns.relplot(df, x='x1', y='x2', hue='y', style='y')\nlogit_plot.figure.subplots_adjust(top=.9)\n\n\n\n\n\n\n\n\n\n\nFitting the logistic regression model\n\nlog_fit = LogisticRegression()\nlog_fit.fit(x, y)\ncoeffs = log_fit.coef_[0]\ncoeff = -coeffs[0]/coeffs[1]\n\n## plot\nlogit_plot = sns.relplot(df, x='x1', y='x2', hue='y', style='y')\nplt.axline([0,0], slope=coeff)\n## title\nlogit_plot.figure.subplots_adjust(top=.9)\nlogit_plot.figure.suptitle(str(round(coeffs[0], 2)) + r'$x_1$ - ' + str(round(-coeffs[1], 2)) + r'$x_2$')\n## fill in area\nx_fill = np.linspace(-2, 2, num=200)\ny_line = coeff * x_fill\nlogit_plot.ax.fill_between(x_fill, y_line, 2, color='blue', alpha=0.2)\nlogit_plot.ax.fill_between(x_fill, -2, y_line, color='orange', alpha=0.2)\n\nlogit_plot.ax.annotate(r'$\\bf P(Y=1)&lt;0.5$', (0.5, 2.1), color='blue')\nlogit_plot.ax.annotate(r'$\\bf P(Y=1)&gt;0.5$', (0.5, -2.2), color='darkorange')",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lec-1/lecture-1.html#principal-components-analysis",
    "href": "lec-1/lecture-1.html#principal-components-analysis",
    "title": "Lecture 1",
    "section": "Principal Components Analysis",
    "text": "Principal Components Analysis\n\npenguins = sns.load_dataset(\"penguins\")\n\nfig = plt.figure()\n\nax = Axes3D(fig)\nfig.add_axes(ax)\n\ncmap = matplotlib.colors.ListedColormap(sns.color_palette(\"Paired\", 3))\n\ncols = penguins['species'].copy()\ncols[cols=='Adelie']=1\ncols[cols=='Chinstrap']=2\ncols[cols=='Gentoo']=3\n\nsc = ax.scatter3D(penguins['bill_depth_mm'],\n                penguins['bill_length_mm'],\n                penguins['flipper_length_mm'],\n                c = cols,\n                cmap=cmap,\n                alpha=1)\nax.set_xlabel('bill depth')\nax.set_ylabel('bill length')\nax.set_zlabel('flipper length')\nax.set_facecolor((1.0, 1.0, 1.0, 0.0))\n\n\n\n\n\n\n\n\n\nx = penguins[['bill_depth_mm', 'bill_length_mm', 'flipper_length_mm']]\nx = x.dropna(axis=0)\n\npca_fit = PCA()\npca_fit.fit(x)\nz = pca_fit.transform(x)\n\nz_df = pd.DataFrame(z[:, 0:2], columns = ['z1', 'z2'])\nz_df['species']=penguins['species']\n\nsns.set_theme()\npca_plot = sns.relplot(z_df, x='z1', y='z2', hue='species', palette=sns.color_palette(\"Paired\", 3), height=4)\n\n\n\n\n\n\n\n\n\nPC_values = np.linspace(1,3,3).reshape(3,1)\nscree_df = np.hstack([PC_values, pca_fit.explained_variance_ratio_.reshape(3,1)])\nscree_df = pd.DataFrame(scree_df, columns = ['Principal Components', 'Explained Variance Ratio'])\nscree_plot = sns.relplot(scree_df, x='Principal Components', y='Explained Variance Ratio', marker='o', kind='line', height=4)",
    "crumbs": [
      "Home",
      "Lecture 1"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "lec-2/lecture-2.html",
    "href": "lec-2/lecture-2.html",
    "title": "Lecture 2",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torchvision\nimport warnings\nwarnings.filterwarnings('ignore')\n\nThe “XOR” (or “exclusive OR”) problem is often used to illustrate the ability of neural networks to fit complicated functions. The XOR problem has a checkerboard structure:\n\n# xor ------------------------------------\nn = 5000\np = 2\nx = np.random.uniform(-2, 2, size=(n, p))\n\n#x[,1] &lt;- first column (R)\n#x[:, 0] &lt;- first column (Python)\n\ny = ((x[:,0] &lt; 0) & (x[:, 1] &gt; 0)).astype(x.dtype) + ((x[:,0] &gt; 0) & (x[:, 1] &lt; 0)).astype(x.dtype)\n\ndf = np.hstack([y.reshape((n, 1)), x])\ndf = pd.DataFrame(df, columns = ['y', 'x1', 'x2'])\n\nsns.set_theme()\nxor_plot = sns.relplot(df, x='x1', y='x2', hue='y', style='y')\nxor_plot.figure.subplots_adjust(top=.9)\n\n\n\n\n\n\n\n\nLogistic regression can only fit linear decision boundaries, and so fails the XOR problem.\n\n## logitstic regression doesn't work\nlog_fit = LogisticRegression()\nlog_fit.fit(x, y)\ncoeffs = log_fit.coef_[0]\ncoeff = -coeffs[0]/coeffs[1]\n\n## plot\nlogit_plot = sns.relplot(df, x='x1', y='x2', hue='y', style='y')\nplt.axline([0,0], slope=coeff)\n## title\nlogit_plot.figure.subplots_adjust(top=.9)\nlogit_plot.figure.suptitle(str(round(coeffs[0], 2)) + r'$x_1$ - ' + str(round(-coeffs[1], 2)) + r'$x_2$')\n## fill in area\nx_fill = np.linspace(-2, 2, num=200)\ny_line = coeff * x_fill\nlogit_plot.ax.fill_between(x_fill, y_line, 2, color='blue', alpha=0.2)\nlogit_plot.ax.fill_between(x_fill, -2, y_line, color='orange', alpha=0.2)\nlogit_plot.ax.set_ylim(-2,2)",
    "crumbs": [
      "Home",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lec-2/lecture-2.html#neural-networks",
    "href": "lec-2/lecture-2.html#neural-networks",
    "title": "Lecture 2",
    "section": "Neural networks",
    "text": "Neural networks\nLet’s set up a 1-layer neural network to solve the XOR problem.\nFor deep learning, we use the torch package, available at https://pytorch.org.\n\nNeural network classes in PyTorch\ntorch provides a base class called nn.Module.\nWhen we set up a neural network, we sub-class nn.Module.\nHere is an example of a neural network in torch named XORNet.\n\nclass XORNet(nn.Module):\n\n    def __init__(self, input_dim, hidden_dim):\n        super(XORNet, self).__init__()\n        self.sequential = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Sigmoid(),\n            nn.Linear(hidden_dim, 1),\n            nn.Sigmoid())\n\n    def forward(self, x):\n        y = self.sequential(x)\n        y = torch.flatten(y)\n        return y\n\n    def loss_fn(self, y, y_pred):\n        loss = y * torch.log(y_pred + 1e-8) + (1-y) * torch.log(1-y_pred + 1e-8)\n        output = -loss.sum()\n        return output\n\nThe class statement identifies the code chunk as a declaration for a class XORNet that inherits from the base class nn.Module. This base class is ubiquitous in torch and represents the mappings in the neural networks.\nIndented beneath the class statement are the methods of this class: in this case __init__, forward and loss_fn. The __init__ method is called when an instance of the class is created. In the methods, self always refers to an instance of the class. In the __init__ method, we have attached an object to self as an attribute: sequential, that defines the neural network architecture.\nThere is one additional line in the __init__ method, which is a call to super(). This function allows subclasses (i.e. XORNet) to access methods of the class they inherit from. For example, the class nn.Module has its own __init__ method, which is different from the XORNet.__init__() method we’ve written above. Using super() allows us to call the method of the base class. For torch models, we will always be making this super() call as it is necessary for the model to be properly interpreted by torch.\nThe function forward is called when the neural network is run on input data.\n(above explanation adapted from https://github.com/intro-stat-learning/ISLP_labs/blob/stable/Ch10-deeplearning-lab.ipynb)\n\nhidden_dim=2\nmodel = XORNet(input_dim=p, hidden_dim=hidden_dim)\n\n\nmodel\n\nXORNet(\n  (sequential): Sequential(\n    (0): Linear(in_features=2, out_features=2, bias=True)\n    (1): Sigmoid()\n    (2): Linear(in_features=2, out_features=1, bias=True)\n    (3): Sigmoid()\n  )\n)\n\n\n\n\nData\nFor torch to read the data, it needs to be a torch.tensor type:\n\nx_train = torch.tensor(x, dtype=torch.float)\ny_train = torch.tensor(y, dtype=torch.float)\n\nWe combine x_train and y_train into a TensorDataset, a dataset recognizable by torch. TensorDataset stores the samples and their labels. It is a subclass of the more general torch.utils.data.Dataset, which you can customize for non-standard data.\n\ntrain_data = TensorDataset(x_train, y_train)\n\nTensorDataset is helpful as it can be passed to DataLoader(). DataLoader wraps an iterable around the Dataset class to enable easy access to the samples. This is very helpful for implementing stochastic gradient descent, where we iterate over subsets (batches) of the data.\n\ntrain_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=True)\n\n\n\nTraining\nWe now set up the optimizer for training. We use Adam, and a base learning rate of lr=0.01. We set the number of epochs to 100. (Rule of thumb: pick largest lr that still results in convergence)\n\nlr = 0.01\nepochs = 100\n\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\n# set model to training mode\nmodel.train()\n\nXORNet(\n  (sequential): Sequential(\n    (0): Linear(in_features=2, out_features=2, bias=True)\n    (1): Sigmoid()\n    (2): Linear(in_features=2, out_features=1, bias=True)\n    (3): Sigmoid()\n  )\n)\n\n\nNow we train the model:\n\nfor epoch in range(epochs):\n    \n    # in each epoch, iterate over all batches of data (easily accessed through train_loader)\n    \n    for x_batch, y_batch in train_loader:\n\n        pred = model(x_batch)                   # this is the output from the forward function\n        loss = model.loss_fn(y_batch, pred)     # calculate loss function\n\n        loss.backward()                         # computes gradients wrt loss function\n        optimizer.step()                        # updates parameters \n        optimizer.zero_grad()                   # set the gradients back to zero (otherwise grads are accumulated)\n\n    if epoch % 10 == 0:\n        print('epoch: ', epoch, 'loss:', f\"{loss.item():.3}\")\n\nepoch:  0 loss: 7.3\nepoch:  10 loss: 6.52\nepoch:  20 loss: 4.98\nepoch:  30 loss: 1.62\nepoch:  40 loss: 1.48\nepoch:  50 loss: 6.74\nepoch:  60 loss: 6.34\nepoch:  70 loss: 7.61\nepoch:  80 loss: 1.87\nepoch:  90 loss: 4.02\n\n\nTo visualize the end result, we plot the predicted values over the whole space (the decision surface).\n\nx1 = np.arange(-2, 2, 0.05)\nx2 = np.arange(-2, 2, 0.05)\n\nx_test_np = np.array([(i, j) for i in x1 for j in x2])\ny_test_np = ((x_test_np[:,0] &lt; 0) & (x_test_np[:, 1] &gt; 0)).astype(x_test_np.dtype) + ((x_test_np[:,0] &gt; 0) & (x_test_np[:, 1] &lt; 0)).astype(x_test_np.dtype)\n\nx_test = torch.tensor(x_test_np, dtype=torch.float)\ny_test = torch.tensor(y_test_np)\n\n\nmodel.eval()\ny_pred = model(x_test)\n\ny_pred_np = y_pred.detach().numpy()\ny_pred_np = y_pred_np.reshape(x1.shape[0], x2.shape[0])\n\nseaborn_cols = sns.color_palette(\"tab10\")\ncols = [seaborn_cols[int(i)] for i in y]\n\ncustom_cmap = sns.diverging_palette(220, 50, s=70, l=70, as_cmap=True)\n\nfig, ax = plt.subplots(1, 1)\nfig.set_size_inches(4, 4)\nax.contourf(x1, x2, y_pred_np, cmap=custom_cmap)\nax.scatter(x[0:100,0], x[0:100,1], c=cols[0:100])\nfig.savefig('xor_nn_d_' + str(hidden_dim) + '.png')\n\n\n\n\n\n\n\n\n\nmodel.sequential[0].weight\n\nParameter containing:\ntensor([[-1.6960,  1.6642],\n        [-2.1710,  2.3189]], requires_grad=True)\n\n\n\nmodel.sequential[0].bias\n\nParameter containing:\ntensor([-3.2356,  3.5178], requires_grad=True)\n\n\n\nmodel.sequential[2].weight\n\nParameter containing:\ntensor([[10.2405, -7.8394]], requires_grad=True)\n\n\nPlay around with different sizes of hidden_dim and see the difference!\n\nmodel.sequential[2].bias\n\nParameter containing:\ntensor([5.3345], requires_grad=True)",
    "crumbs": [
      "Home",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lec-2/lecture-2.html#mnist-example",
    "href": "lec-2/lecture-2.html#mnist-example",
    "title": "Lecture 2",
    "section": "MNIST example",
    "text": "MNIST example\nWe use torchvision.datasets to download the MNIST data.\n\n(mnist_train,\n mnist_test) = [torchvision.datasets.MNIST(root='data',\n                      train=train,\n                      download=True,\n                      transform=torchvision.transforms.ToTensor())\n                for train in [True, False]]\n\nplt.figure(figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    train_image, label = mnist_train[i]\n    plt.imshow(train_image[0], cmap=plt.cm.binary)\n    plt.xlabel(label)\nplt.show()\n\n\n\n\n\n\n\n\nSet up our dataloaders.\n\ntrain_loader = DataLoader(dataset=mnist_train, batch_size=64, shuffle=True)\ntest_loader = DataLoader(dataset=mnist_test, batch_size=10000, shuffle=False)\n\nLet’s define our neural network for the MNIST classification problem.\n\nclass MNISTNet(nn.Module):\n\n    def __init__(self):\n        super(MNISTNet, self).__init__()\n\n        self.layers = nn.Sequential(\n            nn.Linear(28*28, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 10),\n            nn.Softmax()\n        )\n\n    def forward(self, x):\n        prob = self.layers(x)\n        return prob\n\n    def loss_fn(self, y, y_pred):\n        log_pred = torch.log(y_pred + 1e-8)\n        loss = -(log_pred * y).sum(1).mean()\n        return loss\n\nInstantiate our model:\n\nmodel = MNISTNet()\n\nTrain our model:\n\nlr = 0.001\nepochs = 50\n\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\n# set model to training mode\nmodel.train()\n\nfor epoch in range(epochs):\n    for x_batch, y_batch in train_loader:\n\n        x_batch = x_batch.reshape(x_batch.shape[0], 28*28)\n        y_batch = F.one_hot(y_batch, num_classes=10)\n        y_pred = model(x_batch)\n        loss = model.loss_fn(y_batch, y_pred)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    if epoch % 10 == 0:\n        print('epoch: ', epoch, 'loss:', f\"{loss.item():.3}\")\n\nepoch:  0 loss: 0.027\nepoch:  10 loss: 0.0456\nepoch:  20 loss: 6.32e-05\nepoch:  30 loss: 0.0436\nepoch:  40 loss: 2.63e-05\n\n\nCalculate our accuracy:\n\nmodel.eval()\nx_batch, y_batch = next(iter(test_loader))\nx_batch = x_batch.reshape(x_batch.shape[0], 28 * 28)\ny_pred_array = model(x_batch)\ny_pred = torch.argmax(y_pred_array, axis=1)\nacc = (y_pred == y_batch).sum()\nacc = acc / len(y_pred)\n\nLet’s look at some interesting results (code adapted from https://github.com/probml/pyprobml/blob/master/notebooks/book1/13/mlp_mnist_tf.ipynb)\n\n# find interesting test images\nerrors = torch.where(y_pred != y_batch)[0]\ninds1 = range(8)\ninds2 = errors[:8]\ninds = np.concatenate((inds1, inds2))\n\npred_array = y_pred_array.detach().numpy()\n\nnum_rows = 4\nnum_cols = 4\nnum_images = num_rows * num_cols\nplt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n\nfor i in range(num_images):\n    n = inds[i]\n    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    image, label = mnist_test[n]\n    plt.imshow(image[0], cmap=plt.cm.binary)\n    plt.xlabel(label)\n    predicted_label = y_pred[n]\n    if predicted_label == label:\n        color = 'blue'\n    else:\n        color = 'red'\n    plt.xlabel(\"truth={}, pred={}, score={:2.0f}%\".format(\n        label,\n        predicted_label,\n        100 * np.max(pred_array[n])),\n        color=color)\n\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    thisplot = plt.bar(range(10), pred_array[n], color=\"#777777\")\n    plt.ylim([0, 1])\n    predicted_label = np.argmax(pred_array[n])\n    thisplot[predicted_label].set_color('red')\n    thisplot[label].set_color('blue')",
    "crumbs": [
      "Home",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lec-2/lecture-2.html#heteroskedastic-regression",
    "href": "lec-2/lecture-2.html#heteroskedastic-regression",
    "title": "Lecture 2",
    "section": "Heteroskedastic regression",
    "text": "Heteroskedastic regression\nThis code is adapted from https://github.com/probml/pyprobml/blob/master/notebooks/book1/13/mlp_1d_regression_hetero_tfp.ipynb\n\n# Make data\n\nx_range = [-20, 60]  # test\nx_ranges = [[-20, 60]]\nns = [1000]\n\ndef load_dataset():\n    def s(x):  # std of noise\n        g = (x - x_range[0]) / (x_range[1] - x_range[0])\n        return 0.25 + g**2.0\n\n    x = []\n    y = []\n    for i in range(len(ns)):\n        n = ns[i]\n        xr = x_ranges[i]\n        x1 = np.linspace(xr[0], xr[1], n)\n        eps = np.random.randn(n) * s(x1)\n        y1 = (1 * np.sin(0.2 * x1) + 0.1 * x1) + eps\n        x = np.concatenate((x, x1))\n        y = np.concatenate((y, y1))\n    # print(x.shape)\n    x = x[..., np.newaxis]\n    n_test = 150\n    x_test = np.linspace(*x_range, num=n_test).astype(np.float32)\n    x_test = x_test[..., np.newaxis]\n    return y, x, x_test\n\ny, x, x_test = load_dataset()\n\n\nDefine neural network\n\nclass HetNet(nn.Module):\n\n    def __init__(self, input_dim, output_dim, hidden_dims, mean_dims, var_dims):\n        super(HetNet, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.hidden_dim = hidden_dims\n        self.mean_dims = mean_dims\n        self.var_dims = var_dims\n\n        # create backbone\n        current_dim = input_dim\n        self.layers = nn.ModuleList()\n        for i in range(len(hidden_dims)):\n            hdim = hidden_dims[i]\n            self.layers.append(nn.Linear(current_dim, hdim))\n            current_dim = hdim\n\n        # create heads\n        core_dim = hidden_dims[-1]\n        current_dim = core_dim\n        self.mean_layers = nn.ModuleList()\n        for i in range(len(mean_dims)):\n            hdim = mean_dims[i]\n            self.mean_layers.append(nn.Linear(current_dim, hdim))\n            current_dim = hdim\n        self.mean_layers.append(nn.Linear(current_dim, output_dim))\n\n        current_dim = core_dim\n        self.var_layers = nn.ModuleList()\n        for i in range(len(var_dims)):\n            hdim = var_dims[i]\n            self.var_layers.append(nn.Linear(current_dim, hdim))\n            current_dim = hdim\n        self.var_layers.append(nn.Linear(current_dim, output_dim))\n\n    def core_net(self, x):\n        for layer in self.layers:\n            x = F.relu(layer(x))\n        return x\n\n    def mean_net(self, x):\n        for layer in self.mean_layers[:-1]:\n            x = F.relu(layer(x))\n        x = self.mean_layers[-1](x)\n        return x\n\n    def var_net(self, x):\n        for layer in self.var_layers[:-1]:\n            x = F.relu(layer(x))\n        x = self.var_layers[-1](x)\n        return x\n\n    def forward(self, x):\n        mean = self.mean_net(self.core_net(x))\n        log_var = self.var_net(self.core_net(x))\n\n        return mean, log_var\n\n    def loss_fn(self, x, y):\n        mean, log_var = self.forward(x)\n        var = torch.exp(log_var)\n\n        loss = torch.pow(y-mean, 2) / var + log_var\n        out = loss.mean()\n\n        return out\n\nSet up data\n\nx_train = torch.tensor(x, dtype=torch.float)\ny_train = torch.tensor(y, dtype=torch.float)\ny_train = y_train.unsqueeze(-1)\n\ntrain_data = TensorDataset(x_train, y_train)\ntrain_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=True)\n\nInitialize model\n\nhidden_dims = [50, 50]\nmean_dims = [20]\nvar_dims = [20]\nmodel = HetNet(input_dim=1, output_dim=1, hidden_dims=hidden_dims, mean_dims=mean_dims, var_dims=var_dims)\n\nTrain\n\nlr = 0.001\nepochs = 500\n\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\n# set model to training mode\nmodel.train()\n\nfor epoch in range(epochs):\n    for x_batch, y_batch in train_loader:\n\n        loss = model.loss_fn(x_batch, y_batch)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    if epoch % 50 == 0:\n        print('epoch: ', epoch, 'loss:', f\"{loss.item():.3}\")\n\nepoch:  0 loss: 0.616\nepoch:  50 loss: -0.806\nepoch:  100 loss: 0.329\nepoch:  150 loss: 0.142\nepoch:  200 loss: 0.0874\nepoch:  250 loss: -0.403\nepoch:  300 loss: 1.06\nepoch:  350 loss: -0.222\nepoch:  400 loss: -0.614\nepoch:  450 loss: -0.372\n\n\nPlot results\n\nmodel.eval()\nmean, log_var = model(x_train)\nsd = torch.exp(0.5 * log_var)\nmean_np = mean.detach().numpy()\nsd_np = sd.detach().numpy()\n\nfig, ax = plt.subplots(1, 1)\nfig.set_size_inches(6, 4)\nax.plot(x, y, '.', label=\"observed\")\nax.plot(x, mean_np, 'r-')\nax.plot(x, mean_np + 2 * sd_np, 'g-')\nax.plot(x, mean_np - 2 * sd_np, 'g-')",
    "crumbs": [
      "Home",
      "Lecture 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rutgers MSDS-534 - Statistical Learning",
    "section": "",
    "text": "Instructor: Gemma Moran\nInstructor website: link"
  },
  {
    "objectID": "index.html#fall-2025",
    "href": "index.html#fall-2025",
    "title": "Rutgers MSDS-534 - Statistical Learning",
    "section": "",
    "text": "Instructor: Gemma Moran\nInstructor website: link"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Rutgers MSDS-534 - Statistical Learning",
    "section": "Getting started",
    "text": "Getting started\nSee here for details about how to get started with python, VSCode and PyTorch."
  },
  {
    "objectID": "index.html#lectures",
    "href": "index.html#lectures",
    "title": "Rutgers MSDS-534 - Statistical Learning",
    "section": "Lectures",
    "text": "Lectures\nThe code from the lectures is in the left sidebar.\nLecture slides and information about homeworks, office hours etc. can be found on Canvas."
  },
  {
    "objectID": "getting-started/getting-started.html",
    "href": "getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "We will use Python via the Anaconda distribution.\nDownload Anaconda here.\n\n\n\n\n\n\nNote\n\n\n\nThere are a variety of different Python distributions; for statistics and machine learning, we recommend Anaconda as it comes with many useful packages pre-installed.\n(It is also a good idea NOT to use your computer’s pre-installed Python - you don’t want to accidentally change any system settings!)\n\n\nAnaconda requires a few GBs of storage - a more lightweight version is Miniconda, which you can download here.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "getting-started/getting-started.html#anaconda-installation",
    "href": "getting-started/getting-started.html#anaconda-installation",
    "title": "Getting started",
    "section": "",
    "text": "We will use Python via the Anaconda distribution.\nDownload Anaconda here.\n\n\n\n\n\n\nNote\n\n\n\nThere are a variety of different Python distributions; for statistics and machine learning, we recommend Anaconda as it comes with many useful packages pre-installed.\n(It is also a good idea NOT to use your computer’s pre-installed Python - you don’t want to accidentally change any system settings!)\n\n\nAnaconda requires a few GBs of storage - a more lightweight version is Miniconda, which you can download here.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "getting-started/getting-started.html#managing-packages",
    "href": "getting-started/getting-started.html#managing-packages",
    "title": "Getting started",
    "section": "Managing packages",
    "text": "Managing packages\nThere are many open source Python packages for statistics and machine learning.\nTo download packages, two popular package managers are Conda and Pip. Both Conda and Pip come with the Anaconda distribution.\nConda is a general-purpose package management system, designed to build and manage software of any type from any language. This means conda can take advantage of many non-python packages (like BLAS, for linear algebra operations).\nPip is a package manager for python. You may see people using pip with environments using virtualenv or venv.\nWe recommend:\n\nuse a conda environment\nwithin this environment, use conda to install base packages such as pandas and numpy\nif a package is not available via conda, then use pip\n\nSee here for some conda vs pip misconceptions, and why conda is helpful.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "getting-started/getting-started.html#environments",
    "href": "getting-started/getting-started.html#environments",
    "title": "Getting started",
    "section": "Environments",
    "text": "Environments\n\nAbout\nIt is good coding practice to use virtual environments with Python. From this blog:\n\nA Python virtual environment consists of two essential components: the Python interpreter that the virtual environment runs on and a folder containing third-party libraries installed in the virtual environment. These virtual environments are isolated from the other virtual environments, which means any changes on dependencies installed in a virtual environment don’t affect the dependencies of the other virtual environments or the system-wide libraries. Thus, we can create multiple virtual environments with different Python versions, plus different libraries or the same libraries in different versions.\n\n\n\n\nCreating an environment for MSDS-534\nWe recommend creating a virtual environment for your MSDS-534 coding projects. This way, you can have an environment with all the necessary packages and you can easily keep track of what versions of the packages you used.\n\nOpen Terminal (macOS) or a shell\nCreate an environment called msds534 using Conda with the command: conda create --name msds534\nTo install packages in your environment, first activate your environment: conda activate msds534\nThen, install the following packages using the command: conda install numpy pandas scikit-learn matplotlib seaborn jupyter ipykernel\nInstall PyTorch by running the appropriate command from here (for macOS, the command is: pip3 install torch torchvision)\nTo exit your environment: conda deactivate\n\nHere is a helpful cheatsheet for conda environment commands.\nFor more details about the shell / bash, here is a helpful resource.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "getting-started/getting-started.html#vscode",
    "href": "getting-started/getting-started.html#vscode",
    "title": "Getting started",
    "section": "VSCode",
    "text": "VSCode\nThere are a number of Python IDEs (integrated development environments). In class, we will be using VSCode (download here).\n\nDownload lecture-1.ipynb [here] and open it in VSCode.\nTo use your msds534 environment, on the top right hand corner, click “Select Kernel” &gt; “Python Environments” &gt; msds534. If it prompts you to install ipykernel, follow the prompts to install it.\n\nJupyter notebooks (.ipynb files) are useful to combine code cells with text (as markdown cells).\nVSCode also has a Python interactive window (details here).",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "getting-started/getting-started.html#learning-python",
    "href": "getting-started/getting-started.html#learning-python",
    "title": "Getting started",
    "section": "Learning Python",
    "text": "Learning Python\nIn this class, we will assume some familiarity with:\n\nNumpy\nPandas\nObject-oriented programming",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  }
]